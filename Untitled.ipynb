{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own Implementation using InceptionV3 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#includes\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.applications.inception_v3 import InceptionV3 # (139, 139, 3)\n",
    "from scipy.io import loadmat\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import Augmentor\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from mixup_generator import MixupGenerator\n",
    "from keras.layers import Dense,Flatten,GlobalAveragePooling2D,Input,Conv2D, MaxPooling2D,BatchNormalization,AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import random\n",
    "from keras_vggface.vggface import VGGFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "path_dataset = \"../../dataset/imdb_crop/\"\n",
    "path_labels = \"../../dataset/imdb.mat\"\n",
    "\n",
    "\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(path_dataset) if isfile(join(path_dataset, f))]\n",
    "onlyfiles = sorted(onlyfiles)\n",
    "print(len(onlyfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_age(taken, dob):\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "\n",
    "    # assume the photo was taken in the middle of the year\n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1\n",
    "def get_meta(mat_path, db):\n",
    "    meta = loadmat(mat_path)\n",
    "    full_path = meta[db][0, 0][\"full_path\"][0]\n",
    "    dob = meta[db][0, 0][\"dob\"][0]  # Matlab serial date number\n",
    "    gender = meta[db][0, 0][\"gender\"][0]\n",
    "    photo_taken = meta[db][0, 0][\"photo_taken\"][0]  # year\n",
    "    face_score = meta[db][0, 0][\"face_score\"][0]\n",
    "    second_face_score = meta[db][0, 0][\"second_face_score\"][0]\n",
    "    age = [calc_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "\n",
    "    return full_path, dob, gender, photo_taken, face_score, second_face_score, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path, _, _, _, face_score, second_face_score, age = get_meta(path_labels,\"imdb\")\n",
    "full_path = [path[0][3:] for path in full_path]\n",
    "\n",
    "new_age = []\n",
    "new_full_path = []\n",
    "import random\n",
    "\n",
    "for i in range(len(age)):\n",
    "    if face_score[i] > 1.0:\n",
    "        r = random.uniform(0, 1)\n",
    "        if (50>age[i]>40 and r >= 0.70) or (40>age[i]>30 and r >= 0.85) or (30>age[i]>20 and r >= 0.75) or (60>age[i]>50 and r >= 0.4) or age[i] < 20 or age[i] > 60:\n",
    "            new_age.append(min(age[i],100))\n",
    "            new_full_path.append(full_path[i])\n",
    "        \n",
    "age = np.array(new_age)\n",
    "full_path = np.array(new_full_path)\n",
    "        \n",
    "print(\"Original: \" + str(len(age)))\n",
    "print(\"Processed: \" + str(len(new_age)))\n",
    "\n",
    "np.save(\"age\", age)\n",
    "np.save(\"full_path\", full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age = np.load(\"age.npy\")\n",
    "full_path = np.load(\"full_path.npy\")\n",
    "\n",
    "hist = plt.hist(age)\n",
    "\n",
    "age = to_categorical(age,101)\n",
    "\n",
    "print(age[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(full_path, age))\n",
    "random.shuffle(combined)\n",
    "\n",
    "full_path[:], age[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 99, 99, 64)   9408        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 99, 99, 64)   256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 99, 99, 64)   0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 49, 49, 64)   0           activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 49, 49, 64)   4096        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 49, 49, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 49, 49, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 49, 49, 256)  16384       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 49, 49, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 49, 49, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 49, 49, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 49, 49, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 49, 49, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 49, 49, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 49, 49, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 49, 49, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 49, 49, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 49, 49, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 49, 49, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 25, 25, 128)  32768       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 25, 25, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 25, 25, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 25, 25, 512)  131072      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 25, 25, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 25, 25, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 25, 25, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 25, 25, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 25, 25, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 25, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 25, 25, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 25, 25, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 25, 25, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 25, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 25, 25, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 25, 25, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 25, 25, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 25, 25, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 25, 25, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 13, 13, 256)  131072      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 13, 13, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 13, 13, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 13, 13, 1024) 524288      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 13, 13, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 13, 13, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 13, 13, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 13, 13, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 13, 13, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 13, 13, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 13, 13, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 13, 13, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 13, 13, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 13, 13, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 13, 13, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 13, 13, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 13, 13, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 13, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 13, 13, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 13, 13, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 13, 13, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 13, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 13, 13, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 13, 13, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 13, 13, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 13, 13, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 13, 13, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc8 (Dense)                     (None, 101)          206949      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,768,101\n",
      "Trainable params: 206,949\n",
      "Non-trainable params: 23,561,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_class = 101\n",
    "hidden_dim = 1024\n",
    "\n",
    "vgg_model = VGGFace(model='resnet50',include_top=False, input_shape=(197, 197, 3))\n",
    "last_layer = vgg_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "#x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Model(vgg_model.input, out)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 139, 139, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         multiple                  21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               103525    \n",
      "=================================================================\n",
      "Total params: 24,004,485\n",
      "Trainable params: 2,201,701\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(139,139,3))\n",
    "\n",
    "base_model = InceptionV3(include_top =False)\n",
    "\n",
    "\n",
    "base_model_output = base_model(inputs)\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model_output)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "new_output = Dense(nb_class,activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=new_output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_batch = 50000\n",
    "batch_size = 128\n",
    "\n",
    "def getBatch(n, batch_size):\n",
    "    if ((n+1)*batch_size) < len(age):\n",
    "        #for file in full_path[n*batch_size:(n+1)*batch_size]:\n",
    "        #    print(path_dataset+file)\n",
    "        return np.array([cv2.resize(cv2.cvtColor(cv2.imread(path_dataset+file),cv2.COLOR_BGR2RGB),(139,139)) for file in full_path[n*batch_size:(n+1)*batch_size]]) , np.array(age[n*batch_size:(n+1)*batch_size])\n",
    "    else:\n",
    "        print(((n+1)*batch_size))\n",
    "        print(len(onlyfiles))\n",
    "        return False, False\n",
    "    \n",
    "def getValidationData(iterations,batch_size):\n",
    "    return np.array([cv2.resize(cv2.cvtColor(cv2.imread(path_dataset+file),cv2.COLOR_BGR2RGB),(139,139)) for file in full_path[iterations*batch_size:]]) , np.array(age[iterations*batch_size:])\n",
    "\n",
    "#X_train = [cv2.resize(cv2.imread(path_dataset+file),(299,299)) for file in onlyfiles]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "  640/45000 [..............................] - ETA: 12:37 - loss: 4.5567 - acc: 0.0391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c24076287b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#if not X_batch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#if n == 2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#    break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m         compat.as_bytes(options.SerializeToString())) if options else None\n\u001b[1;32m    904\u001b[0m     \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0mfinal_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# We only want to really perform the run if fetches or targets are provided,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'partial_run() requires empty target_list.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             run_metadata, status)\n\u001b[0;32m-> 1420\u001b[0;31m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = int(len(full_path) / bigger_batch)\n",
    "nb_epoch = 5\n",
    "#first without any data stuff\n",
    "val_x, val_y = getValidationData(iterations,bigger_batch)\n",
    "#for e in tqdm(range(nb_epoch)):\n",
    "#for n in range(iterations):\n",
    "X_batch, label = getBatch(0,bigger_batch) # these are chunks of bigger_batch pictures\n",
    "#print(X_batch.shape)\n",
    "print(batch_size)\n",
    "#if not X_batch:\n",
    "    #break\n",
    "model.fit(x=X_batch, y=label, batch_size=batch_size, epochs=5, validation_split=0.1)\n",
    "#if n == 2:\n",
    "#    break\n",
    "\n",
    "model.evaluate(x=val_x, y=val_y, batch_size=batch_size, verbose=10, shuffle = True)\n",
    "model.save_weights(os.path.join(\"models\", \"miracle.h5\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "       layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "for e in tqdm(range(nb_epoch)):\n",
    "    print(\"epoch %d\" % e)\n",
    "    batch = 0\n",
    "    for n in range(iterations):\n",
    "        X_batch, label = getBatch(n,bigger_batch) # these are chunks of bigger_batch pictures\n",
    "        #print(X_batch.shape)\n",
    "        print(batch_size)\n",
    "        #if not X_batch:\n",
    "            #break\n",
    "        model.fit(x=X_batch, y=label, batch_size=batch_size, epochs=5,validation_split=0.1)\n",
    "        #if n == 2:\n",
    "        #    break\n",
    "model.save_weights(os.path.join(\"models\", \"miracle2.h5\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath='test/'\n",
    "testfiles = [ f for f in listdir(testpath) if isfile(join(testpath,f)) ]\n",
    "\n",
    "images = np.empty(len(testfiles), dtype=object)\n",
    "faces = np.empty((len(testfiles), 139, 139, 3))\n",
    "\n",
    "for n in range(0, len(testfiles)):\n",
    "    images[n] = cv2.imread( join(testpath,testfiles[n]))\n",
    "    images[n] = cv2.cvtColor(images[n],cv2.COLOR_BGR2RGB)\n",
    "    faces[n, : , : , :] = cv2.resize(images[n][:,:,:], (139, 139))\n",
    "    \n",
    "results = model.predict(faces)\n",
    "\n",
    "\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages = results.dot(ages).flatten()\n",
    "\n",
    "for n in range(len(testfiles)):\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.resize(images[n], (139, 139)))\n",
    "    print(\"Age of \" + testfiles[n] + \": \" + str(predicted_ages[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
