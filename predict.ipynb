{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from wide_resnet import WideResNet\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# load model and weights\n",
    "img_size64 = 64\n",
    "model64 = WideResNet(img_size64, depth=22, k=8)()\n",
    "model64.load_weights(os.path.join(\"../../dataset/checkpoints\", \"model64.hdf5\"))\n",
    "\n",
    "img_size32 = 32\n",
    "model32 = WideResNet(img_size32, depth=16, k=8)()\n",
    "model32.load_weights(os.path.join(\"../../dataset/checkpoints\", \"model32.hdf5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"wiki\"\n",
    "data = scipy.io.loadmat(os.path.join(\"../../dataset/\", \"{}32.mat\".format(db)))\n",
    "test_images = data[\"image\"]\n",
    "test_genders = data[\"gender\"][0]\n",
    "test_ages = data[\"age\"][0]\n",
    "\n",
    "cols, rows = 4, 3\n",
    "img_num = cols * rows\n",
    "path_root = \"data/{}_crop/\".format(db)\n",
    "img_ids = np.random.choice(len(test_ages), img_num)\n",
    "sub_test_images = test_images[img_ids,:,:,:]\n",
    "\n",
    "# predict\n",
    "results = model32.predict(sub_test_images)\n",
    "predicted_genders = results[0]\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages = results[1].dot(ages).flatten()\n",
    "\n",
    "for i in range(img_num):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(sub_test_images[i,:,:,:], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"{}, {}\".format(int(predicted_ages[i]),\n",
    "                              \"F\" if predicted_genders[i][0]>0.5 else \"M\"))\n",
    "    plt.axis('off')\n",
    "plt.savefig(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath='test/'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "images32 = np.empty(len(onlyfiles), dtype=object)\n",
    "faces32 = np.empty((len(onlyfiles), img_size32, img_size32, 3))\n",
    "images64 = np.empty(len(onlyfiles), dtype=object)\n",
    "faces64 = np.empty((len(onlyfiles), img_size64, img_size64, 3))\n",
    "for n in range(0, len(onlyfiles)):\n",
    "    images32[n] = cv2.imread( join(mypath,onlyfiles[n]))\n",
    "    images32[n] = cv2.cvtColor(images32[n],cv2.COLOR_BGR2RGB)\n",
    "    faces32[n, : , : , :] = cv2.resize(images32[n][35:-35,35:-35,:], (img_size32, img_size32))\n",
    "    \n",
    "    images64[n] = cv2.imread( join(mypath,onlyfiles[n]))\n",
    "    images64[n] = cv2.cvtColor(images64[n],cv2.COLOR_BGR2RGB)\n",
    "    faces64[n, : , : , :] = cv2.resize(images64[n][35:-35,35:-35,:], (img_size64, img_size64))\n",
    "    \n",
    "results32 = model32.predict(faces32)\n",
    "results64 = model64.predict(faces64)\n",
    "predicted_genders32 = results32[0]\n",
    "predicted_genders64 = results64[0]\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages32 = results32[1].dot(ages).flatten()\n",
    "predicted_ages64 = results64[1].dot(ages).flatten()\n",
    "\n",
    "for n in range(len(onlyfiles)):\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.resize(images32[n], (img_size64, img_size64)))\n",
    "    print(\"Age \" +onlyfiles[n]+ \" (32x32): \", int(predicted_ages32[n]))\n",
    "    print(\"Gender \" +onlyfiles[n]+ \" (32x32): \", \"F\" if predicted_genders32[n][0] > 0.5 else \"M\")\n",
    "    plt.figure()\n",
    "    plt.imshow(images64[n])\n",
    "    print(\"Age \" +onlyfiles[n]+ \" (64x64): \", int(predicted_ages64[n]))\n",
    "    print(\"Gender \" +onlyfiles[n]+ \" (64x64): \", \"F\" if predicted_genders64[n][0] > 0.5 else \"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
