{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from wide_resnet import WideResNet\n",
    "from MyModel import MyModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# load model and weights\n",
    "img_size = 224\n",
    "model64 = MyModel(img_size)()\n",
    "model64.load_weights(os.path.join(\"models\", \"WRN_16_8.h5\"))\n",
    "\n",
    "#img_size32 = 32\n",
    "#model32 = WideResNet(img_size32, depth=16, k=8)()\n",
    "#model32.load_weights(os.path.join(\"../../dataset/checkpoints\", \"model32.hdf5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"wiki\"\n",
    "data = scipy.io.loadmat(os.path.join(\"../../dataset/\", \"{}32.mat\".format(db)))\n",
    "test_images = data[\"image\"]\n",
    "test_genders = data[\"gender\"][0]\n",
    "test_ages = data[\"age\"][0]\n",
    "\n",
    "cols, rows = 4, 3\n",
    "img_num = cols * rows\n",
    "path_root = \"data/{}_crop/\".format(db)\n",
    "img_ids = np.random.choice(len(test_ages), img_num)\n",
    "sub_test_images = test_images[img_ids,:,:,:]\n",
    "\n",
    "# predict\n",
    "results = model32.predict(sub_test_images)\n",
    "predicted_genders = results[0]\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages = results[1].dot(ages).flatten()\n",
    "\n",
    "for i in range(img_num):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(sub_test_images[i,:,:,:], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"{}, {}\".format(int(predicted_ages[i]),\n",
    "                              \"F\" if predicted_genders[i][0]>0.5 else \"M\"))\n",
    "    plt.axis('off')\n",
    "plt.savefig(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import face_recognition\n",
    "mypath='test/'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "#images32 = np.empty(len(onlyfiles), dtype=object)\n",
    "#faces32 = np.empty((len(onlyfiles), img_size32, img_size32, 3))\n",
    "images64 = np.empty(len(onlyfiles), dtype=object)\n",
    "faces64 = np.empty((len(onlyfiles), 224, 224, 3))\n",
    "for n in range(0, len(onlyfiles)):\n",
    "   # images32[n] = cv2.imread( join(mypath,onlyfiles[n]))\n",
    "    #images32[n] = cv2.cvtColor(images32[n],cv2.COLOR_BGR2RGB)\n",
    "    #faces32[n, : , : , :] = cv2.resize(images32[n][35:-35,35:-35,:], (img_size32, img_size32))\n",
    "    image = face_recognition.load_image_file(join(mypath,onlyfiles[n]))\n",
    "    face_locations = face_recognition.face_locations(image)[0]\n",
    "    #print(face_locations)\n",
    "    #print(face_locations[0],face_locations[2])\n",
    "    #print(face_locations[3],face_locations[1])\n",
    "    #print(image.shape)\n",
    "    images64[n] = image[face_locations[0]:face_locations[2],face_locations[3]:face_locations[1],:]\n",
    "    faces64[n, : , : , :] = cv2.resize(images64[n], (224, 224))\n",
    "    \n",
    "#results32 = model32.predict(faces32)\n",
    "results64 = model64.predict(faces64)\n",
    "#predicted_genders32 = results32[0]\n",
    "#predicted_genders64 = results64[0]\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "#predicted_ages32 = results32[1].dot(ages).flatten()\n",
    "predicted_ages64 = results64.dot(ages).flatten()\n",
    "\n",
    "for n in range(len(onlyfiles)):\n",
    "    plt.figure()\n",
    "   # plt.imshow(cv2.resize(images32[n], (img_size64, img_size64)))\n",
    "    #print(\"Age \" +onlyfiles[n]+ \" (32x32): \", int(predicted_ages32[n]))\n",
    "    #print(\"Gender \" +onlyfiles[n]+ \" (32x32): \", \"F\" if predicted_genders32[n][0] > 0.5 else \"M\")\n",
    "    plt.figure()\n",
    "    plt.imshow(images64[n])\n",
    "    print(\"Age \" +onlyfiles[n]+ \" (64x64): \", predicted_ages64[n])\n",
    "    #print(\"Gender \" +onlyfiles[n]+ \" (64x64): \", \"F\" if predicted_genders64[n][0] > 0.5 else \"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7594 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    '../../dataset/wiki_crop/new_database/',\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39952594153278903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def x_difference(val_generator, X):\n",
    "    predictions = model64.predict_generator(val_generator)\n",
    "    ages = np.arange(0, 101).reshape(101, 1)\n",
    "    predicted_age = predictions.dot(ages).flatten()\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(val_generator.classes)):\n",
    "        real_label = val_generator.classes[i]\n",
    "        if abs(real_label - predicted_age[i]) < X:\n",
    "            counter += 1\n",
    "            \n",
    "    return counter / len(val_generator.classes)\n",
    "\n",
    "print(x_difference(val_generator,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
